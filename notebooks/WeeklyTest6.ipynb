{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9d9737616514b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Az eredményeket mentsd a src/weekly modul-ba weekly_test_6.py néven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9789db8f0fbd7ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Használható modulok: pathlib, pandas, typing, str, statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea6e648868022e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datalib = Path.cwd().parent.joinpath('data')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b5dd4685315eda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26aec7b4e97407",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1., Olvasd be a data mappa sp500.parquet nevű fájlját egy DataFrame-be. A betöltéshez használt engine paramétere legyen fastparquet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/sp500.parquet\"\n",
    "\n",
    "df = pd.read_parquet(file_path, engine=\"fastparquet\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:27:13.383502Z",
     "start_time": "2023-10-25T17:27:13.288168Z"
    }
   },
   "id": "43f685fc4780d23a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2., Olvasd be az ff_factors.parquet fájlt egy DataFrame-be. A betöltéshez használt engine paramétere legyen fastparquet\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d42ee754b557dcef"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/ff_factors.parquet\"\n",
    "\n",
    "df = pd.read_parquet(file_path, engine=\"fastparquet\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:28:39.484248Z",
     "start_time": "2023-10-25T17:28:39.412592Z"
    }
   },
   "id": "c757103536fa82f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c977da040d844",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3., Kapcsold össze a két DataFrame-t egy új DataFrame-be. Az összekapcsolás módja, hogy a hozam adatokra balról kapcsoljuk rá a factor adatokat a 'Date' elsődleges kulcs alapján.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Joined data](../resources/weekly6/joined_data.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf54c6765186a23e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Első DataFrame (sp500.parquet) beolvasása\n",
    "sp500_df = pd.read_parquet(\"../data/sp500.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "# Második DataFrame (ff_factors.parquet) beolvasása\n",
    "ff_df = pd.read_parquet(\"../data/ff_factors.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "# Összekapcsolás a 'Date' kulcs alapján\n",
    "merged_df = sp500_df.merge(ff_df, on='Date', how='left')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:31:33.174008Z",
     "start_time": "2023-10-25T17:31:33.054342Z"
    }
   },
   "id": "34bc40351687c32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10fafbf699543d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4., Készíts egy új 'Excess Return' nevű oszlopot, ami a havi hozamok és a kockázat mentes hozam (RF) különbsége\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Módosított DataFrame létrehozása az \"Excess Return\" oszloppal\n",
    "merged_df['Excess Return'] = merged_df['Monthly Returns'] - merged_df['RF']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:34:48.028666Z",
     "start_time": "2023-10-25T17:34:47.979276Z"
    }
   },
   "id": "fdc8822a72cb19f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5., Rendezd sorba dátum szerint az adatokat, majd generálj egy új oszlopot ('ex_ret_1'), amely minden ticker ('Symbol') esetén 1-el eltolja az Excess Return értékeit olyan módon, hogy minden sorban szerepeljen a következő időszaki Excess Return érték. \n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6af93a4a3c53398"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![new column](../resources/weekly6/ex_ret_1.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be746933376572"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Dátum szerinti rendezés,  ezt raktam be\n",
    "merged_df = merged_df.sort_values(by=['Symbol', 'Date'])\n",
    "\n",
    "# Az \"Excess Return\" értékek 1-el való eltolása minden \"Symbol\" csoporton belül\n",
    "merged_df['ex_ret_1'] = merged_df.groupby('Symbol')['Excess Return'].shift(-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:38:48.592569Z",
     "start_time": "2023-10-25T17:38:48.450339Z"
    }
   },
   "id": "1ea1a61ee4262715"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Első lépés: rendezzük sorba a DataFrame-t dátum szerint\n",
    "merged_df.sort_values(by=['Symbol', 'Date'], inplace=True)\n",
    "\n",
    "# Második lépés: csoportosítsuk a DataFrame-t a 'Symbol' oszlop alapján\n",
    "grouped = merged_df.groupby('Symbol')\n",
    "\n",
    "# Harmadik lépés: alkossunk egy új oszlopot, amely tartalmazza az eltolást\n",
    "merged_df['ex_ret_1'] = grouped['Excess Return'].shift(-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:38:53.050977Z",
     "start_time": "2023-10-25T17:38:52.971524Z"
    }
   },
   "id": "2285003630c207d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd1aa0c59afb47",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6., A meglévő adathalmazt írd felül olyan módon, hogy egyszer törlöd az össze olyan sort, amely az 'ex_ret_1' oszlopban hiányos, majd ezt követően, törlöd az összes olyan sort, ami a 'HML' oszlopban hiányos\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Hiányzó értékek törlése az 'ex_ret_1' oszlopban\n",
    "merged_df = merged_df.dropna(subset=['ex_ret_1'])\n",
    "\n",
    "# Hiányzó értékek törlése a 'HML' oszlopban\n",
    "merged_df = merged_df.dropna(subset=['HML'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T17:44:39.765562Z",
     "start_time": "2023-10-25T17:44:39.693135Z"
    }
   },
   "id": "fbc765e1bf390d09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Töröljük a 'Symbol' oszlopot\n",
    "merged_df.drop('Symbol', axis=1, inplace=True)\n",
    "\n",
    "# Válasszuk ki az 'AMZN' részvényhez tartozó sorokat\n",
    "amazon_df = merged_df[merged_df['Symbol'] == 'AMZN']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c05ad228230923e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f333cdfad16d315f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4637c401e0e6352c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A meglévő adatokból válaszd ki a Amazon részvényhez tartozó sorokat (AMZN) és töröld a tickereket tartalmazó oszlopot\n",
    "\n",
    "7., Készíts egy új LinearRegressionSM elnevezésű osztályt. Definiáld benne a __init__ nevű függvényt, amely bemenetként 2 DataDrame-t kap amelyeket ments le a left_hand_side és right_hand_side elnevezésű változókba. Az egyik DataFrame fogja tartalmazni a következő hónap többlet hozamait (left_hand_side), a másik a piaci hozamokat (Mkt-RF), az SMB és a HML értékeket (right_hand_side).\n",
    "\n",
    "8., Egésztsd ki az osztályt egy fit metódussal, ami meghívja a statsmodels segítségével OLS alapon becsült modellt illeszt az osztály adattagjaira. A becslésből visszakapott modellt mentse le az osztály _model adattagjába. Figyelj oda, hogy a regresszió futtatása során konstans (alfa / béta_0) is szerepeljen a predictor változók között.\n",
    "\n",
    "9., Egészítsd ki az osztályt egy get_params metódussal, ami visszaadja a becsült modellt béta paramétereinek értékeit. A visszakapott pandas Series típusú adatban az oszlop neve legyen 'Beta coefficients'\n",
    "\n",
    "10., Egészítsd ki az osztályt egy get_pvalues metódussal, ami visszaadja a becsült modell paraméterekhez tartozó p értékeket. A visszakapott pandas Series típusú adatban az oszlop neve legyen: P-values for the corresponding coefficients\n",
    "\n",
    "11., Egészítsd ki az osztályt egy get_wald_test_result metódussal, ami visszaadja a bemeneti restrikciós mátrix alapján számolt F és p értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: F-value: fvalue, p-value: pvalue, ahol az fvalue és pvalue helyére 3 tizedesjegyre kerekítve adja meg a hozzájuk tartozó értékeket.\n",
    "\n",
    "12., Egészítse ki az osztályt egy get_model_goodness_values metódussal, ami visszadja a módosított R-négyzet, az Akaike és a Bayes információs kritériumok értékét. A visszatérési típus string legyen, a visszaadandó szöveg: Adjusted R-squared: ars, Akaike IC: ak, Bayes IC: by, ahol ars, ak és by helyére 3 tizedesjegyre kerekítve adja meg a hozzájuk tartozó értékeket.\n",
    "\n",
    "A létrehozott osztályt és a hozzátartozó metódusokat mentsd le a src.linear_regression mappába, a LinearRegressions.py fájlba.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Töröljük a 'Symbol' oszlopot\n",
    "merged_df.drop('Symbol', axis=1, inplace=True)\n",
    "\n",
    "# Válasszuk ki az 'AMZN' részvényhez tartozó sorokat\n",
    "amazon_df = merged_df[merged_df['Symbol'] == 'AMZN']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d391a7a1e93f9df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Amazon részvényhez tartozó sorok kiválasztása (AMZN)\n",
    "amazon_df = merged_df[merged_df['Symbol'] == 'AMZN']\n",
    "\n",
    "# Ticker oszlop törlése\n",
    "amazon_df = amazon_df.drop(columns=['Symbol'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "632e9b84be1a75ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LinearRegressionSM:\n",
    "    def __init__(self, left_hand_side, right_hand_side):\n",
    "        self.left_hand_side = left_hand_side\n",
    "        self.right_hand_side = right_hand_side\n",
    "        self._model = None\n",
    "\n",
    "    def fit(self):\n",
    "        formula = \"left_hand_side ~ Mkt_RF + SMB + HML\"\n",
    "        model = ols(formula=formula, data=self.right_hand_side).fit()\n",
    "        self._model = model\n",
    "\n",
    "    def get_params(self):\n",
    "        # Az illesztett modell koefficienseinek lekérése és elnevezése\n",
    "        beta_params = self._model.params.rename(\"Beta coefficients\")\n",
    "        return beta_params\n",
    "\n",
    "\n",
    "    def get_pvalues(self):\n",
    "        p_values = self._model.pvalues.rename(\"P-values for the corresponding coefficients\")\n",
    "        return p_values\n",
    "\n",
    "\n",
    "    def get_wald_test_result(self, constraint_matrix):\n",
    "        wald_result = self._model.wald_test(constraint_matrix)\n",
    "        f_value = wald_result.statistic[0, 0]\n",
    "        p_value = wald_result.pvalue\n",
    "\n",
    "        result_text = f\"F-value: {f_value:.3f}, p-value: {p_value:.3f}\"\n",
    "\n",
    "        return result_text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d83d3b1f9cf207b7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
