{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9d9737616514b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Az osztály(oka)t mentsd a __src/linear_regression__ modul __LinearRegressions.py__ fájljába\n",
    "Használható modulok: _pathlib, pandas, typing, str, numpy, scipy.stats t_ és _norm_, valamint a _scipy.optimize_ _minimize_ osztályai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7066ec7a2294843b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea6e648868022e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datalib = Path.cwd().parent.joinpath('data')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b5dd4685315eda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adatelőkészítés (0 pont)\n",
    "1., Olvasd be a data mappa __sp500.parquet__ nevű fájlját egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "2., Olvasd be az __ff_factors.parquet__ fájlt egy DataFrame-be. A betöltéshez használt engine paramétere legyen <u>fastparquet</u>\n",
    "3., Kapcsold össze a két DataFrame-t egy új DataFrame-be. Az összekapcsolás módja, hogy a hozam adatokra balról kapcsoljuk rá a factor adatokat a __'Date' elsődleges kulcs__ alapján.\n",
    "4., Készíts egy új __'Excess Return'__ nevű oszlopot, ami a havi hozamok és a kockázat mentes hozam (RF) különbsége\n",
    "5., <u>Rendezd sorba dátum szerint az adatokat</u>, majd generálj egy új oszlopot (__'ex_ret_1'__), amely minden ticker ('Symbol') esetén 1-el eltolja az Excess Return értékeit olyan módon, hogy minden sorban szerepeljen a <u>következő időszaki Excess Return</u> érték. \n",
    "6., A meglévő adathalmazt írd felül olyan módon, hogy egyszer <u>törlöd az össze olyan sort</u>, amely az __'ex_ret_1' oszlopban hiányos__, majd ezt követően, törlöd az összes olyan sort, ami a __'HML' oszlopban hiányos__.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad5a013c358987e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. feladat segítség\n",
    "![Joined data](../resources/weekly6/joined_data.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf54c6765186a23e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. feladat segítség\n",
    "![new column](../resources/weekly6/ex_ret_1.jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6be746933376572"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "760e41517a8f96ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modell összeállítás (7 pont)\n",
    "\n",
    "A meglévő adatokból válaszd ki a __Amazon részvényhez tartozó sorokat (AMZN)__ és töröld a tickereket tartalmazó oszlopot. <u>Amennyiben működött, önellenőrzésre használhatod a legutóbbi zárthelyin írt osztályt is.</u>\n",
    "\n",
    "7., Készíts egy új __LinearRegressionML__ elnevezésű osztályt. Definiáld benne a __\\_\\_init\\_\\___ nevű függvényt, amely bemenetként 2 DataFrame-t kap amelyeket ments le a left_hand_side és right_hand_side elnevezésű változókba. Az egyik DataFrame fogja tartalmazni a következő hónap többlet hozamait (__left_hand_side__), a másik a piaci hozamokat (Mkt-RF), az SMB és a HML értékeket (__right_hand_side__).\n",
    "\n",
    "8., Egésztsd ki az osztályt egy __fit__ metódussal, ami ML elvű becslést hajt végre. Figyelj oda, hogy a regresszió futtatása során konstans (alfa / béta_0) is szerepeljen a predictor változók között, amely az első változó legyen. __A feladatot numerikus optimalizálással old meg, analítikus megoldásra nem ját pont__\n",
    "\n",
    "9., Egészítsd ki az osztályt egy __get_params__ metódussal, ami visszaadja a becsült modell béta paramétereinek értékeit. A visszakapott pandas Series típusú adatban az oszlop neve legyen __Beta coefficients__. \n",
    "\n",
    "10., Egészítsd ki az osztályt egy __get_pvalues__ metódussal, ami visszaadja a becsült modell paraméterekhez tartozó p értékeket. A visszakapott pandas Series típusú adatban az oszlop neve legyen: __P-values for the corresponding coefficients__. A p értéket t-statisztika alapján számold ki. A p-érték kiszámításánál figyelj, hogy  alkalmazd a <u>min(value, 1-value) * 2</u> képletet.\n",
    "\n",
    "11., Egészítse ki az osztályt egy __get_model_goodness_values__ metódussal, ami visszadja a centrált és a módosított R-négyzet értékeket. A visszatérési típus string legyen, a visszaadandó szöveg: __Centered R-squared: crs, Adjusted R-squared: ars__, ahol crs és ars helyére 3 tizedesjegyre kerekítve (__:.3f__) add meg a hozzájuk tartozó értékeket. <u>Ha a regresszorok számába eredetileg beleszámítottad a konstanst is, akkor a módosított R-négyzet számítás nevezőjében nincs szükség a __-1__-es tagra</u>."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1888d0ef54d4b2c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Kiegészítés:\n",
    "- Mivel a célparaméterek kicsik, a minimalizálás kiinduló értékeit érdemes egységesen, minden paraméter számára __0.1__-re állítani.\n",
    "- Javasolt a __L-BFGS-B__ optimalizáló alkalmazása\n",
    "- Ne felejtsd el, hogy az MLE __variancia becslése torzított__. A kapott eredményeket ennek megfelelően korrigáld."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5636fb7cd43f4897"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    def get_pvalues(self):\n",
    "        # Calculate p-values for coefficients\n",
    "        self.fit()\n",
    "        degrees_of_freedom = len(self.observed_values) - self.design_matrix.shape[1]\n",
    "        residuals = self.observed_values - self.design_matrix @ self.coefficients\n",
    "        residual_var = (residuals @ residuals) / degrees_of_freedom\n",
    "        t_stat = self.coefficients / np.sqrt(np.diag(residual_var * np.linalg.inv(self.design_matrix.T @ self.weights_inv @ self.design_matrix)))\n",
    "\n",
    "        # Calculate two-tailed p-values using the t distribution\n",
    "        p_values = pd.Series([min(value, 1 - value) * 2 for value in t.cdf(-np.abs(t_stat), df=degrees_of_freedom)],\n",
    "                             name='P-values for the corresponding coefficients')\n",
    "        return p_values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b74aa975a3c02d04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    def get_pvalues(self):\n",
    "        self.fit()\n",
    "        degrees_of_freedom = len(self.left_hand_side) - len(self.coefficients)\n",
    "        residuals = self.left_hand_side.values.flatten() - np.dot(np.column_stack((np.ones_like(self.left_hand_side), self.right_hand_side.values)), self.coefficients)\n",
    "        residual_var = (residuals @ residuals) / degrees_of_freedom\n",
    "        t_stat = self.coefficients / np.sqrt(np.diag(residual_var * np.linalg.inv(np.dot(np.column_stack((np.ones_like(self.left_hand_side), self.right_hand_side.values)).T, np.column_stack((np.ones_like(self.left_hand_side), self.right_hand_side.values))))))\n",
    "\n",
    "        # Calculate two-tailed p-values using the t distribution\n",
    "        p_values = pd.Series([min(value, 1 - value) * 2 for value in norm.cdf(-np.abs(t_stat))],\n",
    "                             name='P-values for the corresponding coefficients')\n",
    "        return p_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import t\n",
    "\n",
    "class LinearRegressionML:\n",
    "    def __init__(self, left_hand_side: pd.DataFrame, right_hand_side: pd.DataFrame):\n",
    "        self.left_hand_side = left_hand_side\n",
    "        self.right_hand_side = right_hand_side\n",
    "        self.coefficients = None\n",
    "\n",
    "    def _negative_log_likelihood(self, params: np.ndarray) -> float:\n",
    "        y = self.left_hand_side.values.flatten()\n",
    "        X = np.column_stack((np.ones_like(y), self.right_hand_side.values))\n",
    "        mu = np.dot(X, params)\n",
    "        neg_log_likelihood = -np.sum(norm.logpdf(y, loc=mu))\n",
    "        return neg_log_likelihood\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        initial_guess = 0.1 * np.ones(self.right_hand_side.shape[1] + 1)\n",
    "        result = minimize(self._negative_log_likelihood, initial_guess, method='L-BFGS-B')\n",
    "        self.coefficients = result.x\n",
    "\n",
    "    def get_params(self, include_intercept: Optional[bool] = True) -> pd.Series:\n",
    "        if self.coefficients is None:\n",
    "            raise ValueError(\"A modell még nincs illesztve. Kérlek, hajtsd végre a fit metódust.\")\n",
    "\n",
    "        param_names = ['Intercept' if include_intercept else '']\n",
    "        param_names += [f'Beta_{i}' for i in range(1, len(self.coefficients))]\n",
    "\n",
    "        return pd.Series(self.coefficients, index=param_names)\n",
    "\n",
    "\n",
    "\n",
    "    def get_pvalues(self):\n",
    "        self.fit()\n",
    "\n",
    "        # Calculate residuals and degrees of freedom\n",
    "        residuals = self.left_hand_side.values.flatten() - np.dot(np.column_stack((np.ones_like(self.left_hand_side), self.right_hand_side.values)), self.coefficients)\n",
    "        degrees_of_freedom = len(self.left_hand_side) - len(self.coefficients)\n",
    "\n",
    "        # Calculate MLE-based variance\n",
    "        residual_var = np.sum((residuals / np.sqrt(degrees_of_freedom))**2) / len(residuals)\n",
    "\n",
    "        # Calculate standard errors\n",
    "        se = np.sqrt(np.diag(residual_var * np.linalg.inv(np.dot(np.column_stack((np.ones_like(self.left_hand_side), self.right_hand_side.values)).T, np.column_stack((np.ones_like(self.left_hand_side), self.right_hand_side.values))))))\n",
    "\n",
    "        # Calculate t-statistic\n",
    "        t_stat = self.coefficients / se\n",
    "\n",
    "        # Calculate two-tailed p-values using the t-distribution\n",
    "        p_values = 2 * (1 - t.cdf(np.abs(t_stat), degrees_of_freedom))\n",
    "\n",
    "        # Create a DataFrame for p-values\n",
    "        p_values_df = pd.DataFrame({'Coefficient': self.coefficient_names, 'P-value': p_values})\n",
    "\n",
    "        return p_values_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f51c210ce9f5a788"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
